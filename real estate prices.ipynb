{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Курсовой проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы к проекту (файлы):\n",
    "train.csv\n",
    "test.csv\n",
    "\n",
    "Задание:\n",
    "Используя данные из train.csv, построить\n",
    "модель для предсказания цен на недвижимость (квартиры).\n",
    "С помощью полученной модели предсказать\n",
    "цены для квартир из файла test.csv.\n",
    "\n",
    "Целевая переменная:\n",
    "Price\n",
    "\n",
    "Метрика:\n",
    "R2 - коэффициент детерминации (sklearn.metrics.r2_score)\n",
    "\n",
    "Сдача проекта:\n",
    "1. Прислать в раздел Задания Урока 10 (\"Вебинар. Консультация по итоговому проекту\")\n",
    "ссылку на программу в github (программа должна содержаться в файле Jupyter Notebook \n",
    "с расширением ipynb). (Pull request не нужен, только ссылка ведущая на сам скрипт).\n",
    "2. Приложить файл с названием по образцу SShirkin_predictions.csv\n",
    "с предсказанными ценами для квартир из test.csv (файл должен содержать два поля: Id, Price).\n",
    "В файле с предсказаниями должна быть 5001 строка (шапка + 5000 предсказаний).\n",
    "\n",
    "Сроки и условия сдачи:\n",
    "Дедлайн: сдать проект нужно в течение 72 часов после начала Урока 10 (\"Вебинар. Консультация по итоговому проекту\").\n",
    "Для успешной сдачи должны быть все предсказания (для 5000 квартир) и R2 должен быть больше 0.6.\n",
    "При сдаче до дедлайна результат проекта может попасть в топ лучших результатов.\n",
    "Повторная сдача и проверка результатов возможны только при условии предыдущей неуспешной сдачи.\n",
    "Успешный проект нельзя пересдать в целях повышения результата.\n",
    "Проекты, сданные после дедлайна или сданные повторно, не попадают в топ лучших результатов, но можно узнать результат.\n",
    "В качестве итогового результата берется первый успешный результат, последующие успешные результаты не учитываются.\n",
    "\n",
    "Примечание:\n",
    "Все файлы csv должны содержать названия полей (header - то есть \"шапку\"),\n",
    "разделитель - запятая. В файлах не должны содержаться индексы из датафрейма.\n",
    "\n",
    "Рекомендации для файла с кодом (ipynb):\n",
    "1. Файл должен содержать заголовки и комментарии\n",
    "2. Повторяющиеся операции лучше оформлять в виде функций\n",
    "3. Не делать вывод большого количества строк таблиц (5-10 достаточно)\n",
    "4. По возможности добавлять графики, описывающие данные (около 3-5)\n",
    "5. Добавлять только лучшую модель, то есть не включать в код все варианты решения проекта\n",
    "6. Скрипт проекта должен отрабатывать от начала и до конца (от загрузки данных до выгрузки предсказаний)\n",
    "7. Весь проект должен быть в одном скрипте (файл ipynb).\n",
    "8. При использовании статистик (среднее, медиана и т.д.) в качестве признаков,\n",
    "лучше считать их на трейне, и потом на валидационных и тестовых данных не считать \n",
    "статистики заново, а брать их с трейна. Если хватает знаний, можно использовать кросс-валидацию,\n",
    "но для сдачи этого проекта достаточно разбить данные из train.csv на train и valid.\n",
    "9. Проект должен полностью отрабатывать за разумное время (не больше 10 минут),\n",
    "поэтому в финальный вариант лучше не включать GridSearch с перебором \n",
    "большого количества сочетаний параметров.\n",
    "10. Допускается применение библиотек Python и моделей машинного обучения,\n",
    "которые были в курсе Python для Data Science. Градиентный бустинг изучается\n",
    "в последующих курсах, поэтому в этом проекте его применять не следует.\n",
    "Самая сложная из допустимых моделей - RandomForestRegressor из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем данные для обучения модели\n",
    "\n",
    "data = pd.read_csv('C:/Users/Enns/Desktop/train.csv', index_col=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square</th>\n",
       "      <th>LifeSquare</th>\n",
       "      <th>KitchenSquare</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HouseFloor</th>\n",
       "      <th>HouseYear</th>\n",
       "      <th>Ecology_1</th>\n",
       "      <th>Ecology_2</th>\n",
       "      <th>Ecology_3</th>\n",
       "      <th>Social_1</th>\n",
       "      <th>Social_2</th>\n",
       "      <th>Social_3</th>\n",
       "      <th>Healthcare_1</th>\n",
       "      <th>Helthcare_2</th>\n",
       "      <th>Shops_1</th>\n",
       "      <th>Shops_2</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14038</th>\n",
       "      <td>35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.981561</td>\n",
       "      <td>29.442751</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1969</td>\n",
       "      <td>0.089040</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>33</td>\n",
       "      <td>7976</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>184966.930730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15053</th>\n",
       "      <td>41</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.683640</td>\n",
       "      <td>40.049543</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1978</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>46</td>\n",
       "      <td>10309</td>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>B</td>\n",
       "      <td>300009.450063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.947953</td>\n",
       "      <td>29.197612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>34</td>\n",
       "      <td>7759</td>\n",
       "      <td>0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>220925.908524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5809</th>\n",
       "      <td>58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.352981</td>\n",
       "      <td>52.731512</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.437885</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>23</td>\n",
       "      <td>5735</td>\n",
       "      <td>3</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>175616.227217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.649192</td>\n",
       "      <td>23.776169</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.012339</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>35</td>\n",
       "      <td>5776</td>\n",
       "      <td>1</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>150226.531644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12915</th>\n",
       "      <td>59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.384479</td>\n",
       "      <td>46.683720</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.309479</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>35</td>\n",
       "      <td>7715</td>\n",
       "      <td>4</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>215898.447742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14549</th>\n",
       "      <td>154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.254114</td>\n",
       "      <td>37.160377</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.460556</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>4386</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>296021.204377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11993</th>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.312926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.075779</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>221244.156664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.511437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>229102.795999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.461409</td>\n",
       "      <td>18.915552</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.075779</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>95380.220993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DistrictId  Rooms     Square  LifeSquare  KitchenSquare  Floor  \\\n",
       "Id                                                                      \n",
       "14038          35    2.0  47.981561   29.442751            6.0      7   \n",
       "15053          41    3.0  65.683640   40.049543            8.0      7   \n",
       "4765           53    2.0  44.947953   29.197612            0.0      8   \n",
       "5809           58    2.0  53.352981   52.731512            9.0      8   \n",
       "10783          99    1.0  39.649192   23.776169            7.0     11   \n",
       "12915          59    3.0  80.384479   46.683720           12.0      5   \n",
       "14549         154    2.0  62.254114   37.160377            7.0      3   \n",
       "11993          74    2.0  80.312926         NaN            0.0     14   \n",
       "5172            1    2.0  64.511437         NaN            1.0      9   \n",
       "8649           23    1.0  46.461409   18.915552            8.0     13   \n",
       "\n",
       "       HouseFloor  HouseYear  Ecology_1 Ecology_2 Ecology_3  Social_1  \\\n",
       "Id                                                                      \n",
       "14038         9.0       1969   0.089040         B         B        33   \n",
       "15053         9.0       1978   0.000070         B         B        46   \n",
       "4765         12.0       1968   0.049637         B         B        34   \n",
       "5809         17.0       1977   0.437885         B         B        23   \n",
       "10783        12.0       1976   0.012339         B         B        35   \n",
       "12915        17.0       2011   0.309479         B         B        35   \n",
       "14549         5.0       1960   0.460556         B         B        20   \n",
       "11993         0.0       1977   0.075779         B         B         6   \n",
       "5172         17.0       1977   0.007122         B         B         1   \n",
       "8649         17.0       2014   0.075779         B         B         6   \n",
       "\n",
       "       Social_2  Social_3  Healthcare_1  Helthcare_2  Shops_1 Shops_2  \\\n",
       "Id                                                                      \n",
       "14038      7976         5           NaN            0       11       B   \n",
       "15053     10309         1         240.0            1       16       B   \n",
       "4765       7759         0         229.0            1        3       B   \n",
       "5809       5735         3        1084.0            0        5       B   \n",
       "10783      5776         1        2078.0            2        4       B   \n",
       "12915      7715         4         990.0            0        6       B   \n",
       "14549      4386        14           NaN            1        5       B   \n",
       "11993      1437         3           NaN            0        2       B   \n",
       "5172        264         0           NaN            0        1       B   \n",
       "8649       1437         3           NaN            0        2       B   \n",
       "\n",
       "               Price  \n",
       "Id                    \n",
       "14038  184966.930730  \n",
       "15053  300009.450063  \n",
       "4765   220925.908524  \n",
       "5809   175616.227217  \n",
       "10783  150226.531644  \n",
       "12915  215898.447742  \n",
       "14549  296021.204377  \n",
       "11993  221244.156664  \n",
       "5172   229102.795999  \n",
       "8649    95380.220993  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем на экран первые 10 записей и убедимся в успешном импорте данных\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 14038 to 6306\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   DistrictId     10000 non-null  int64  \n",
      " 1   Rooms          10000 non-null  float64\n",
      " 2   Square         10000 non-null  float64\n",
      " 3   LifeSquare     7887 non-null   float64\n",
      " 4   KitchenSquare  10000 non-null  float64\n",
      " 5   Floor          10000 non-null  int64  \n",
      " 6   HouseFloor     10000 non-null  float64\n",
      " 7   HouseYear      10000 non-null  int64  \n",
      " 8   Ecology_1      10000 non-null  float64\n",
      " 9   Ecology_2      10000 non-null  object \n",
      " 10  Ecology_3      10000 non-null  object \n",
      " 11  Social_1       10000 non-null  int64  \n",
      " 12  Social_2       10000 non-null  int64  \n",
      " 13  Social_3       10000 non-null  int64  \n",
      " 14  Healthcare_1   5202 non-null   float64\n",
      " 15  Helthcare_2    10000 non-null  int64  \n",
      " 16  Shops_1        10000 non-null  int64  \n",
      " 17  Shops_2        10000 non-null  object \n",
      " 18  Price          10000 non-null  float64\n",
      "dtypes: float64(8), int64(8), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# выведем информацию о данных и проверим наличие пропусков\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проведем минимальную чистку и предобработку данных\n",
    "# построим несколько моделей и оценим качество на отложенной выборке по метрике R^2\n",
    "# из построенных модель выберем baseline модель с наилучшим качеством\n",
    "# заполним пропуски нулями\n",
    "\n",
    "cleared_data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleared_data.drop(labels=['Price'], axis=1)\n",
    "X = pd.get_dummies(data=X, columns=['DistrictId', 'Ecology_2', 'Ecology_3', 'Shops_2'], drop_first=True)\n",
    "y = cleared_data['Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: \n",
      "\ttrain: 0.6759 \n",
      "\tvalid: 0.5829\n",
      "knn: \n",
      "\ttrain: 0.7495 \n",
      "\tvalid: 0.5906\n",
      "dt: \n",
      "\ttrain: 1.0 \n",
      "\tvalid: 0.5297\n",
      "rf: \n",
      "\ttrain: 0.9615 \n",
      "\tvalid: 0.716\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "   'lr': LinearRegression(),\n",
    "#    'lasso': Lasso(random_state=42),\n",
    "#    'ridge': Ridge(random_state=42),\n",
    "#    'enet': ElasticNet(random_state=42),\n",
    "   'knn': KNeighborsRegressor(),\n",
    "   'dt': DecisionTreeRegressor(random_state=42),\n",
    "   'rf': RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "score_list = []\n",
    "\n",
    "for model in model_dict:\n",
    "    model_dict[model].fit(X_train_scaled, y_train)\n",
    "    y_pred_train = model_dict[model].predict(X_train_scaled)\n",
    "    y_pred_valid = model_dict[model].predict(X_valid_scaled)\n",
    "    score_train = r2_score(y_train, y_pred_train)\n",
    "    score_valid = r2_score(y_valid, y_pred_valid)\n",
    "    score_list.append((score_train, score_valid))\n",
    "\n",
    "for model, scores in zip(model_dict.keys(), score_list):\n",
    "    print(f'{model}: \\n\\ttrain: {np.round(scores[0], 4)} \\n\\tvalid: {np.round(scores[1], 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# с минимальной педобработкой данных лучший результат \"из коробки\" показала модель RandomForest\n",
    "# baseline R^2 = 0.7006\n",
    "# попробуем очистить и обработать имеющиеся данные\n",
    "# продолжим работать с моделью RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистим данные\n",
    "\n",
    "cleared_data = data[data['Rooms'] < 10]\n",
    "cleared_data = cleared_data[cleared_data['Square'] < 250]\n",
    "cleared_data = cleared_data[cleared_data['HouseFloor'] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию для предобработки данных\n",
    "\n",
    "def preproc(df_input, dummy_features=None):\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "        \n",
    "    Square = dict(df_output.groupby('Rooms')['Square'].median())\n",
    "    idx = (df_output['Square'] < 15) & (df_output['Rooms'] < 2)\n",
    "    df_output.loc[idx, 'Square'] = df_output.loc[idx, 'Rooms'].apply(lambda x: Square[x])\n",
    "    \n",
    "    idx = (df_output['Square'] < 30) & (df_output['Rooms'] > 1)\n",
    "    df_output.loc[idx, 'Square'] = df_output.loc[idx, 'Rooms'].apply(lambda x: Square[x])\n",
    "    \n",
    "    idx = (df_output['Square'] < df_output['LifeSquare'])\n",
    "    df_output.loc[idx, 'Square'] = df_output.loc[idx, 'LifeSquare']\n",
    "\n",
    "    LifeSquare = dict(df_output.groupby('Rooms')['LifeSquare'].median())\n",
    "    idx = (df_output['LifeSquare'].isnull())\n",
    "    df_output.loc[idx, 'LifeSquare'] = df_output.loc[idx, 'Rooms'].apply(lambda x: LifeSquare[x])\n",
    "\n",
    "    idx = (df_output['Rooms'] < 1)\n",
    "    df_output.loc[idx, 'KitchenSquare'] = 0.0\n",
    "    \n",
    "    KitchenSquare = dict(df_output.groupby('Rooms')['KitchenSquare'].median())\n",
    "    idx = (df_output['Rooms'] > 0)\n",
    "    df_output.loc[idx, 'KitchenSquare'] = df_output.loc[idx, 'Rooms'].apply(lambda x: KitchenSquare[x])\n",
    "    \n",
    "    idx = (df_output['HouseFloor'] < df_output['Floor'])\n",
    "    df_output.loc[idx, 'HouseFloor'] = df_output.loc[idx, 'Floor']\n",
    "    \n",
    "    idx = (df_output['HouseYear'] >= 2019)\n",
    "    df_output.loc[idx, 'HouseYear'] = 2019\n",
    "   \n",
    "    df_output['Healthcare_1'].fillna(df_output['Healthcare_1'].median(), inplace=True)\n",
    "    \n",
    "    df_output['Ecology_2'] = df_output['Ecology_2'].apply(lambda x: 1 if x == 'A' else 0)\n",
    "    df_output['Ecology_3'] = df_output['Ecology_3'].apply(lambda x: 1 if x == 'A' else 0)\n",
    "    df_output['Shops_2'] = df_output['Shops_2'].apply(lambda x: 1 if x == 'A' else 0)\n",
    "    \n",
    "    if dummy_features != None:\n",
    "        df_output = pd.get_dummies(data=df_output, columns=dummy_features, drop_first=True)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработаем данные для использования в модели\n",
    "\n",
    "processed_data = preproc(cleared_data, dummy_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_data.drop(labels=['DistrictId', 'Price'], axis=1)\n",
    "y = processed_data['Price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "0.7245491107392947\n",
      "{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 0.5, 'max_depth': 26}\n"
     ]
    }
   ],
   "source": [
    "# проведем настройку гиперпараметров модели с помощью RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': np.arange(200, 501, 20),\n",
    "    'max_depth': np.arange(2, 51, 2),\n",
    "    'max_features': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=50,\n",
    "    scoring='r2',\n",
    "    cv=10,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9376\n",
      "valid: 0.7169\n"
     ]
    }
   ],
   "source": [
    "# измерим качество подобранной модели на отложенной выборке\n",
    "\n",
    "y_pred_train = random_search.best_estimator_.predict(X_train_scaled)\n",
    "y_pred_valid = random_search.best_estimator_.predict(X_valid_scaled)\n",
    "\n",
    "score_train = r2_score(y_train, y_pred_train)\n",
    "score_valid = r2_score(y_valid, y_pred_valid)\n",
    "\n",
    "print(f'train: {np.round(score_train, 4)}\\nvalid: {np.round(score_valid, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv mean: 0.7357\n",
      "cv std:  0.0243\n"
     ]
    }
   ],
   "source": [
    "# обучим подобранную модель на всех тренировочных данных\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=26,\n",
    "    max_features=0.5,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "scores = cross_val_score(model, X_scaled, y, scoring='r2', cv=10, n_jobs=-1)\n",
    "\n",
    "print(f'cv mean: {np.round(np.mean(scores), 4)}')\n",
    "print(f'cv std:  {np.round(np.std(scores), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим неразмеченные данные для предсказания\n",
    "\n",
    "new_data = pd.read_csv('C:/Users/Enns/Desktop/test.csv', index_col=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square</th>\n",
       "      <th>LifeSquare</th>\n",
       "      <th>KitchenSquare</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HouseFloor</th>\n",
       "      <th>HouseYear</th>\n",
       "      <th>Ecology_1</th>\n",
       "      <th>Ecology_2</th>\n",
       "      <th>Ecology_3</th>\n",
       "      <th>Social_1</th>\n",
       "      <th>Social_2</th>\n",
       "      <th>Social_3</th>\n",
       "      <th>Healthcare_1</th>\n",
       "      <th>Helthcare_2</th>\n",
       "      <th>Shops_1</th>\n",
       "      <th>Shops_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>58</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.882643</td>\n",
       "      <td>33.432782</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1972</td>\n",
       "      <td>0.310199</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>11</td>\n",
       "      <td>2748</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.263183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0.075779</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5480</th>\n",
       "      <td>190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.597819</td>\n",
       "      <td>15.948246</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>30</td>\n",
       "      <td>7538</td>\n",
       "      <td>87</td>\n",
       "      <td>4702.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73.046609</td>\n",
       "      <td>51.940842</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.101872</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>23</td>\n",
       "      <td>4583</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.527111</td>\n",
       "      <td>43.387569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.072158</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>629</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DistrictId  Rooms     Square  LifeSquare  KitchenSquare  Floor  \\\n",
       "Id                                                                      \n",
       "725            58    2.0  49.882643   33.432782            6.0      6   \n",
       "15856          74    2.0  69.263183         NaN            1.0      6   \n",
       "5480          190    1.0  13.597819   15.948246           12.0      2   \n",
       "15664          47    2.0  73.046609   51.940842            9.0     22   \n",
       "14275          27    1.0  47.527111   43.387569            1.0     17   \n",
       "\n",
       "       HouseFloor  HouseYear  Ecology_1 Ecology_2 Ecology_3  Social_1  \\\n",
       "Id                                                                      \n",
       "725          14.0       1972   0.310199         B         B        11   \n",
       "15856         1.0       1977   0.075779         B         B         6   \n",
       "5480          5.0       1909   0.000000         B         B        30   \n",
       "15664        22.0       2007   0.101872         B         B        23   \n",
       "14275        17.0       2017   0.072158         B         B         2   \n",
       "\n",
       "       Social_2  Social_3  Healthcare_1  Helthcare_2  Shops_1 Shops_2  \n",
       "Id                                                                     \n",
       "725        2748         1           NaN            0        0       B  \n",
       "15856      1437         3           NaN            0        2       B  \n",
       "5480       7538        87        4702.0            5        5       B  \n",
       "15664      4583         3           NaN            3        3       B  \n",
       "14275       629         1           NaN            0        0       A  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# убедимся, что данные загрузились\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработаем новые данные тем же спопосбом, что и данные на которых обучали модель\n",
    "\n",
    "processed_new_data = preproc(new_data, dummy_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = processed_new_data.drop(labels=['DistrictId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# масштабируем новые данные подготовленным на тренировочных данных объектом класса MinMaxScaler\n",
    "\n",
    "X_new_scaled = scaler.transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предскажем цены квартир для новых наблюдений\n",
    "\n",
    "y_pred_new = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем id объекта и предсказанную цену в датафрейм\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'Id': X_new.index,\n",
    "    'Price': y_pred_new\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>725</td>\n",
       "      <td>159716.003524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15856</td>\n",
       "      <td>205133.085284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5480</td>\n",
       "      <td>272968.271945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15664</td>\n",
       "      <td>350647.142002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14275</td>\n",
       "      <td>136769.439246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id          Price\n",
       "0    725  159716.003524\n",
       "1  15856  205133.085284\n",
       "2   5480  272968.271945\n",
       "3  15664  350647.142002\n",
       "4  14275  136769.439246"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним предсказания в csv файл\n",
    "\n",
    "predictions.to_csv('SShirkin_predictions.csv', sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "452c276e810072ac0d070a9ecbd74ba181ab2f9a45b11b5d9d043df0d8e763c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
